\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{torch}
\@writefile{toc}{\contentsline {section}{\numberline {1} Feedforward Neural Networks}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Preliminary Concepts}{1}{subsection.1.1}\protected@file@percent }
\newlabel{PC}{{1.1}{1}{Preliminary Concepts}{subsection.1.1}{}}
\newlabel{fig:nnpic}{{1.1}{2}{Preliminary Concepts}{subsection.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Mathematical Foundations}{2}{subsection.1.2}\protected@file@percent }
\newlabel{MF}{{1.2}{2}{Mathematical Foundations}{subsection.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Motivation}{2}{subsubsection.1.2.1}\protected@file@percent }
\newlabel{mt}{{1.2.1}{2}{Motivation}{subsubsection.1.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A neural network with two layers; two inpus in the first layer no hidden layer and one output in the output layer}}{3}{figure.1}\protected@file@percent }
\newlabel{eq:model}{{1}{3}{Motivation}{equation.1.1}{}}
\newlabel{eq:cost}{{2}{3}{Motivation}{equation.1.2}{}}
\citation{DnnBook}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Gradient Based Learning}{6}{subsubsection.1.2.2}\protected@file@percent }
\newlabel{sec:GBL}{{1.2.2}{6}{Gradient Based Learning}{subsubsection.1.2.2}{}}
\newlabel{fig:FCL}{{1.2.2}{6}{Gradient Based Learning}{subsubsection.1.2.2}{}}
\newlabel{zwa}{{4a}{7}{Gradient Based Learning}{equation.1.4a}{}}
\newlabel{act}{{4b}{7}{Gradient Based Learning}{equation.1.4b}{}}
\newlabel{fig:output}{{1.2.2}{8}{Gradient Based Learning}{equation.1.7}{}}
\newlabel{fe1}{{9}{8}{Gradient Based Learning}{equation.1.9}{}}
\newlabel{FE1}{{10}{8}{Gradient Based Learning}{equation.1.10}{}}
\citation{adam}
\newlabel{FE2}{{12}{9}{Gradient Based Learning}{equation.1.12}{}}
\newlabel{FE3}{{13}{9}{Gradient Based Learning}{equation.1.13}{}}
\newlabel{FE4}{{14}{9}{Gradient Based Learning}{equation.1.14}{}}
\newlabel{alg:GD}{{1.2.2}{10}{Gradient Based Learning}{equation.1.14}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Gradient Decent for a Feed Forward Network}}{10}{algorithm.1}\protected@file@percent }
\newlabel{fig:sigmo}{{1}{10}{Gradient Based Learning}{Item.9}{}}
\newlabel{fig:relu}{{3}{11}{Gradient Based Learning}{Item.11}{}}
\newlabel{cf}{{16}{11}{Gradient Based Learning}{equation.1.16}{}}
\newlabel{CF}{{17}{12}{Gradient Based Learning}{equation.1.17}{}}
\newlabel{eq:bgd}{{19}{12}{Gradient Based Learning}{equation.1.19}{}}
\newlabel{VG}{{21}{12}{Gradient Based Learning}{equation.1.21}{}}
\newlabel{CE}{{22}{12}{Gradient Based Learning}{equation.1.22}{}}
\newlabel{eq:ce}{{23}{13}{Gradient Based Learning}{equation.1.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Convolution Neural Networks(CNN)}{13}{section.2}\protected@file@percent }
\newlabel{CNN}{{2}{13}{Convolution Neural Networks(CNN)}{section.2}{}}
\citation{IP}
\newlabel{introCNN}{{2}{14}{Introduction}{section*.2}{}}
\newlabel{eq;conv}{{26}{14}{Introduction}{equation.2.26}{}}
\newlabel{eq;dconv}{{27}{14}{Introduction}{equation.2.27}{}}
\newlabel{pic:conv}{{2}{14}{Introduction}{equation.2.27}{}}
\newlabel{fig:edge}{{2}{15}{Introduction}{equation.2.27}{}}
\newlabel{fig:cnn}{{2}{16}{Introduction}{equation.2.27}{}}
\newlabel{eq:dcon}{{28}{16}{Introduction}{equation.2.28}{}}
\newlabel{fig:convp}{{2}{17}{Introduction}{equation.2.29b}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Back Propagation in CNN Models}{17}{subsection.2.1}\protected@file@percent }
\newlabel{eq:cnnE1}{{30}{17}{Back Propagation in CNN Models}{equation.2.30}{}}
\newlabel{eq:cnnE2}{{32}{17}{Back Propagation in CNN Models}{equation.2.32}{}}
\newlabel{eq:cnnE3}{{33}{17}{Back Propagation in CNN Models}{equation.2.33}{}}
\citation{alexnet}
\citation{imagenet}
\newlabel{eq:cnnE4}{{34}{18}{Back Propagation in CNN Models}{equation.2.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Overfitting and Underfitting}{18}{section.3}\protected@file@percent }
\newlabel{sec:overunder}{{3}{18}{Overfitting and Underfitting}{section.3}{}}
\newlabel{fig:alex}{{3}{18}{Overfitting and Underfitting}{section.3}{}}
\citation{prac}
\citation{fund}
\newlabel{fig:overfit}{{3}{19}{Overfitting and Underfitting}{section.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Improving Neural Networks}{19}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Momentum Based Gradient Decent}{19}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Regularization}{20}{subsection.4.2}\protected@file@percent }
\newlabel{eq:l2}{{36a}{20}{Regularization}{equation.4.36a}{}}
\newlabel{eq:l1}{{36b}{20}{Regularization}{equation.4.36b}{}}
\newlabel{eq:sgdL2}{{37}{20}{Regularization}{equation.4.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Dropout}{20}{subsection.4.3}\protected@file@percent }
\newlabel{fig:drop}{{4.3}{21}{Dropout}{subsection.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Early Stopping}{21}{subsection.4.4}\protected@file@percent }
\newlabel{fig:overfit2}{{4.4}{21}{Early Stopping}{subsection.4.4}{}}
\citation{lecun}
\citation{batchnorm}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Preprocessing}{22}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Shuffling}{22}{subsection.4.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Batch Normalization}{22}{subsection.4.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8}Data Augmentation}{22}{subsection.4.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9}Transfer Learning}{23}{subsection.4.9}\protected@file@percent }
\newlabel{fig:overfit2}{{4.9}{23}{Transfer Learning}{subsection.4.9}{}}
\citation{intel}
\citation{vgg16}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.10}Hyper Parameter Optimization}{24}{subsection.4.10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}An Image Classification Problem}{24}{section.5}\protected@file@percent }
\citation{tb}
\citation{pandas}
\citation{intel1}
\citation{optuna}
\citation{syms}
\citation{segment}
\bibstyle{unsrt}
\bibdata{report}
\bibcite{torch}{1}
\bibcite{DnnBook}{2}
\bibcite{adam}{3}
\bibcite{IP}{4}
\bibcite{alexnet}{5}
\bibcite{imagenet}{6}
\bibcite{prac}{7}
\bibcite{fund}{8}
\newlabel{eq:hspace}{{39}{25}{An Image Classification Problem}{equation.5.39}{}}
\bibcite{lecun}{9}
\bibcite{batchnorm}{10}
\bibcite{intel}{11}
\bibcite{vgg16}{12}
\bibcite{tb}{13}
\bibcite{pandas}{14}
\bibcite{intel1}{15}
\bibcite{optuna}{16}
\bibcite{syms}{17}
\bibcite{segment}{18}
